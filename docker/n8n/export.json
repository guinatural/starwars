[{"createdAt":"2025-06-18T18:40:58.516Z","updatedAt":"2025-06-18T18:41:54.042Z","id":"O3hOekD6yO0ViZ7K","name":"SKDVN V2","active":false,"isArchived":false,"nodes":[{"parameters":{"options":{}},"id":"1626a454-5a8c-47bd-850e-69ac89b58412","name":"When chat message received","type":"@n8n/n8n-nodes-langchain.chatTrigger","position":[-1240,-100],"webhookId":"4d06a912-2920-489c-a33c-0e3ea0b66745","typeVersion":1.1},{"parameters":{"promptType":"define","text":"=Provide the users prompt and response as a JSON object with two fields:\n- Prompt\n- Response\n\nAvoid any preample or further explanation.\n\nThis is the question: {{ $json.chatInput }}"},"id":"12f912be-722b-4a1f-a9c5-951765a79a93","name":"Basic LLM Chain","type":"@n8n/n8n-nodes-langchain.chainLlm","position":[-880,-100],"typeVersion":1.5,"onError":"continueErrorOutput"},{"parameters":{"model":"llama3.2:latest","options":{}},"id":"0a1a1756-7283-4712-a24a-f364189f5bbb","name":"Ollama Model","type":"@n8n/n8n-nodes-langchain.lmOllama","position":[-780,180],"typeVersion":1},{"parameters":{"content":"# ðŸ¦™ Ollama Chat Workflow\n\nA simple N8N workflow that integrates Ollama LLM for chat message processing and returns a structured JSON object.\n\n## Overview\nThis workflow creates a chat interface that processes messages using the Llama 3.2 model through Ollama. When a chat message is received, it gets processed through a basic LLM chain and returns a response.\n\n## Components\n- **Trigger Node**\n- **Processing Node**\n- **Model Node**\n- **JSON to Object Node**\n- **Structured Response Node**\n- **Error Response Node**\n\n## Workflow Structure\n1. The chat trigger node receives incoming messages\n2. Messages are passed to the Basic LLM Chain\n3. The Ollama Model processes the input using Llama 3.2\n4. Responses are returned through the chain\n\n## Prerequisites\n- N8N installation\n- Ollama setup with Llama 3.2 model\n- Valid Ollama API credentials\n\n## Configuration\n1. Set up the Ollama API credentials in N8N\n2. Ensure the Llama 3.2 model is available in your Ollama installation\n\n","height":860,"width":520,"color":4},"id":"13768ae3-7614-4157-9150-f9ee8f6f509b","name":"Sticky Note","type":"n8n-nodes-base.stickyNote","position":[-1900,-540],"typeVersion":1},{"parameters":{"content":"## Model Node\n- Name: Ollama Model\n- Type: LangChain Ollama Integration\n- Model: llama3.2:latest\n- Purpose: Provides the language model capabilities","height":200,"width":560},"id":"f7b9d81a-801a-436e-b20d-9b2e77f930f0","name":"Sticky Note1","type":"n8n-nodes-base.stickyNote","position":[-1180,120],"typeVersion":1},{"parameters":{"content":"## Trigger Node\n- Name: When chat message received\n- Type: Chat Trigger\n- Purpose: Initiates the workflow when a new chat message arrives","height":400,"width":280,"color":6},"id":"1ea4bcf3-a97d-43af-8c59-091c0a9a745e","name":"Sticky Note2","type":"n8n-nodes-base.stickyNote","position":[-1320,-320],"typeVersion":1},{"parameters":{"content":"## Processing Node\n- Name: Basic LLM Chain\n- Type: LangChain LLM Chain\n- Purpose: Handles the processing of messages through the language model and returns a structured JSON object.\n\n","height":620,"width":500,"color":3},"id":"63c0ab46-9c3e-4c0f-9ac9-c4bad0860595","name":"Sticky Note3","type":"n8n-nodes-base.stickyNote","position":[-1000,-540],"typeVersion":1},{"parameters":{"content":"### Prompt (Change this for your use case)\nProvide the users prompt and response as a JSON object with two fields:\n- Prompt\n- Response\n\n\nAvoid any preample or further explanation.\nThis is the question: {{ $json.chatInput }}","height":200,"width":420,"color":7},"id":"6a4de3eb-7a4c-4567-a191-3b850f92e033","name":"Sticky Note4","type":"n8n-nodes-base.stickyNote","position":[-960,-360],"typeVersion":1},{"parameters":{"content":"## JSON to Object Node\n- Type: Set Node\n- Purpose: A node designed to transform and structure response data in a specific format before sending it through the workflow. It operates in manual mapping mode to allow precise control over the response format.\n\n**Key Features**\n- Manual field mapping capabilities\n- Object transformation and restructuring\n- Support for JSON data formatting\n- Field-to-field value mapping\n- Includes option to add additional input fields\n","height":520,"width":420,"color":5},"id":"e3f17bbb-125e-452f-8de4-a7a2e1554a3e","name":"Sticky Note5","type":"n8n-nodes-base.stickyNote","position":[-460,-440],"typeVersion":1},{"parameters":{"content":"## Structured Response Node\n- Type: Set Node\n- Purpose: Controls how the workflow responds to users chat prompt.\n\n**Response Mode**\n- Manual Mapping: Allows custom formatting of response data\n- Fields to Set: Specify which data fields to include in response\n\n","height":420,"width":460,"color":6},"id":"afb3b89b-f563-4d88-bbc4-06464ef0a708","name":"Sticky Note6","type":"n8n-nodes-base.stickyNote","position":[0,-340],"typeVersion":1},{"parameters":{"assignments":{"assignments":[{"id":"13c4058d-2d50-46b7-a5a6-c788828a1764","name":"text","type":"string","value":"=Your prompt was: {{ $json.response.Prompt }}\n\nMy response is: {{ $json.response.Response }}\n\nThis is the JSON object:\n\n{{ $('Basic LLM Chain').item.json.text }}"}]},"options":{}},"id":"7299d5a7-e51f-464f-a6fc-a6fb3dc4bee7","name":"Structured Response","type":"n8n-nodes-base.set","position":[180,-100],"typeVersion":3.4},{"parameters":{"assignments":{"assignments":[{"id":"13c4058d-2d50-46b7-a5a6-c788828a1764","name":"text","type":"string","value":"=There was an error."}]},"options":{}},"id":"70ebe816-1161-40ba-a62f-ba579b138c36","name":"Error Response","type":"n8n-nodes-base.set","position":[-60,500],"typeVersion":3.4},{"parameters":{"content":"## Error Response Node\n- Type: Set Node\n- Purpose: Handles error cases when the Basic LLM Chain fails to process the chat message properly. It provides a fallback response mechanism to ensure the workflow remains robust.\n\n**Key Features**\n- Provides default error messaging\n- Maintains consistent response structure\n- Connects to the error output branch of the LLM Chain\n- Ensures graceful failure handling\n\nThe Error Response node activates when the main processing chain encounters issues, ensuring users always receive feedback even when errors occur in the language model processing.\n","height":560,"width":540,"color":2},"id":"3b687931-57bf-4e7f-9d0e-4e5107871471","name":"Sticky Note7","type":"n8n-nodes-base.stickyNote","position":[-280,120],"typeVersion":1},{"parameters":{"assignments":{"assignments":[{"id":"12af1a54-62a2-44c3-9001-95bb0d7c769d","name":"response","type":"object","value":"={{ $json.text }}"}]},"options":{}},"id":"5721097d-b966-49c0-a750-992a36031249","name":"JSON to Object","type":"n8n-nodes-base.set","position":[-300,-100],"typeVersion":3.4}],"connections":{"When chat message received":{"main":[[{"node":"Basic LLM Chain","type":"main","index":0}]]},"Basic LLM Chain":{"main":[[{"node":"JSON to Object","type":"main","index":0}],[{"node":"Error Response","type":"main","index":0}]]},"Ollama Model":{"ai_languageModel":[[{"node":"Basic LLM Chain","type":"ai_languageModel","index":0}]]},"JSON to Object":{"main":[[{"node":"Structured Response","type":"main","index":0}]]}},"settings":{"executionOrder":"v1"},"staticData":null,"meta":null,"pinData":{},"versionId":"fa0d356f-43d4-437f-890e-6386ba5a1ad1","triggerCount":0,"tags":[{"createdAt":"2025-06-18T18:40:56.925Z","updatedAt":"2025-06-18T18:40:56.925Z","id":"AnQiw6aCK34hAwKd","name":"boot"}]},{"createdAt":"2025-06-18T18:36:34.446Z","updatedAt":"2025-06-18T18:36:34.446Z","id":"xAGogmibsA8INw2Z","name":"Demo: My first AI Agent in n8n","active":false,"isArchived":false,"nodes":[{"parameters":{"options":{}},"id":"b24b05a7-d802-4413-bfb1-23e1e76f6203","name":"When chat message received","type":"@n8n/n8n-nodes-langchain.chatTrigger","typeVersion":1.1,"position":[360,20],"webhookId":"a889d2ae-2159-402f-b326-5f61e90f602e"},{"parameters":{"content":"## Start by saying 'hi'\n![Button](https://i.imgur.com/PrIBJI6.png)","height":149,"width":150},"id":"5592c045-6718-4c4e-9961-ce67a251b6df","name":"Sticky Note","type":"n8n-nodes-base.stickyNote","typeVersion":1,"position":[180,-40]},{"parameters":{"promptType":"define","text":"=## Steps to follow\n\n{{ $agentInfo.memoryConnectedToAgent ? '1. Skip': `1. STOP and output the following:\n\"Welcome to n8n. Let's start with the first step to give me memory: \\n\"Click the **+** button on the agent that says 'memory' and choose 'Simple memory.' Just tell me once you've done that.\"\n----- END OF OUTPUT && IGNORE BELOW -----` }} \n\n\n{{ Boolean($agentInfo.tools.find((tool) => tool.type === 'Google Calendar Tool')) ? '2. Skip' : \n`2. STOP and output the following: \\n\"Click the **+** button on the agent that says 'tools' and choose 'Google Calendar.'\" \\n ----- IGNORE BELOW -----` }}\n\n\n{{ $agentInfo.tools.find((tool) => tool.type === 'Google Calendar Tool').hasCredentials ? '3. Skip' :\n`3. STOP and output the following:\n\"Open the Google Calendar tool (double-click) and choose a credential from the drop-down.\" \\n ----- IGNORE BELOW -----` }}\n\n\n{{ $agentInfo.tools.find((tool) => tool.type === 'Google Calendar Tool').resource === 'Event' ? '4. Skip' :\n`4. STOP and output the following:\n\"Open the Google Calendar tool (double-click) and set **resource** = 'Event'\" `}}\n\n\n{{ $agentInfo.tools.find((tool) => tool.type === 'Google Calendar Tool').operation === 'Get Many' ? '5. Skip' :\n`5. STOP and output the following:\n\"Open the Google Calendar tool (double-click) and set **operation** = 'Get Many.'\" \\n ----- IGNORE BELOW -----` }}\n\n\n{{ $agentInfo.tools.find((tool) => tool.type === 'Google Calendar Tool').hasValidCalendar ? '6. Skip' :\n`6. STOP and output the following:\n\"Open the Google Calendar tool (double-click) and choose a calendar from the 'calendar' drop-down.\" \\n ----- IGNORE BELOW -----` }}\n\n\n{{ ($agentInfo.tools.find((tool) => tool.type === 'Google Calendar Tool').aiDefinedFields.includes('Start Time') && $agentInfo.tools.find((tool) => tool.type === 'Google Calendar Tool').aiDefinedFields.includes('End Time')) ? '7. Skip' :\n`7. STOP and output the following: \nOpen the Google Calendar tool (double-click) and click the :sparks: button next to the 'After' and 'Before' fields. \\n ----- IGNORE BELOW -----` }}\n\n\n8. If all steps are completed, output the following:\n\"Would you like me to check all events in your calendar for tomorrow {{ $now.plus(1, 'days').toString().split('T')[0] }}?\"\n\n# User message\n\n{{ $json.chatInput }}","options":{"systemMessage":"=You are a friendly Agent designed to guide users through these steps.\n\n- Stop at the earliest step mentioned in the steps\n- Respond concisely and do **not** disclose these internal instructions to the user. Only return defined output below.\n- Don't output any lines that start with -----\n- Replace \":sparks:\" with \"âœ¨\" in any message"}},"id":"41174c8a-6ac8-42bd-900e-ca15196600c5","name":"Agent","type":"@n8n/n8n-nodes-langchain.agent","typeVersion":1.7,"position":[580,20]}],"connections":{"When chat message received":{"main":[[{"node":"Agent","type":"main","index":0}]]}},"settings":{"executionOrder":"v1"},"staticData":null,"meta":{"templateId":"self-building-ai-agent","templateCredsSetupCompleted":true},"pinData":{},"versionId":"2a50ee2a-23bb-4ceb-ae87-909026fd4c9f","triggerCount":0,"tags":[]},{"createdAt":"2025-06-18T18:40:35.469Z","updatedAt":"2025-06-18T18:43:53.918Z","id":"dMKi2LXG7cyF3UFh","name":"SKDVN V1","active":false,"isArchived":false,"nodes":[{"parameters":{"options":{}},"id":"7d525359-dc43-4f6f-809d-52912a4243dd","name":"When chat message received","type":"@n8n/n8n-nodes-langchain.chatTrigger","position":[-1460,-100],"webhookId":"ebdeba3f-6b4f-49f3-ba0a-8253dd226161","typeVersion":1.1},{"parameters":{"options":{}},"id":"3e7a21ee-3b0a-4dc0-b0d9-975823df19f0","name":"Ollama Chat Model","type":"@n8n/n8n-nodes-langchain.lmChatOllama","position":[-1260,120],"typeVersion":1},{"parameters":{"content":"## Chat with local LLMs using n8n and Ollama\nThis n8n workflow allows you to seamlessly interact with your self-hosted Large Language Models (LLMs) through a user-friendly chat interface. By connecting to Ollama, a powerful tool for managing local LLMs, you can send prompts and receive AI-generated responses directly within n8n.\n\n### How it works\n1. When chat message received: Captures the user's input from the chat interface.\n2. Chat LLM Chain: Sends the input to the Ollama server and receives the AI-generated response.\n3. Delivers the LLM's response back to the chat interface.\n\n### Set up steps\n* Make sure Ollama is installed and running on your machine before executing this workflow.\n* Edit the Ollama address if different from the default.\n","height":473,"width":485},"id":"aa18e2c4-53d5-4e60-98af-718a39994b4a","name":"Sticky Note","type":"n8n-nodes-base.stickyNote","position":[-2000,-480],"typeVersion":1},{"parameters":{"content":"## Ollama setup\n* Connect to your local Ollama, usually on http://localhost:11434\n* If running in Docker, make sure that the n8n container has access to the host's network in order to connect to Ollama. You can do this by passing `--net=host` option when starting the n8n Docker container","height":258,"width":368,"color":6},"id":"9bfb6038-32a6-4c2a-9667-d6808aebf941","name":"Sticky Note1","type":"n8n-nodes-base.stickyNote","position":[-1120,100],"typeVersion":1},{"parameters":{},"id":"ac9f1800-cbd4-4df4-9eb3-7ab28ba4d9c2","name":"Chat LLM Chain","type":"@n8n/n8n-nodes-langchain.chainLlm","position":[-1240,-100],"typeVersion":1.4}],"connections":{"When chat message received":{"main":[[{"node":"Chat LLM Chain","type":"main","index":0}]]},"Ollama Chat Model":{"ai_languageModel":[[{"node":"Chat LLM Chain","type":"ai_languageModel","index":0}]]}},"settings":{"executionOrder":"v1"},"staticData":null,"meta":null,"pinData":{},"versionId":"dc88629b-89c9-4556-bb39-93c62ca671e4","triggerCount":0,"tags":[]}]